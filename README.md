# Data Intake - ServiÃ§o de ExtraÃ§Ã£o e Chunking

Este projeto implementa um serviÃ§o completo de extraÃ§Ã£o e chunking de documentos usando NestJS, LangChain, OpenAI/Azure OpenAI e ChromaDB.

## ğŸš€ Funcionalidades

- **ExtraÃ§Ã£o de Documentos**: Suporte para PDF, Excel, Texto e HTML
- **Chunking Inteligente**: MÃºltiplas estratÃ©gias de divisÃ£o de texto
- **GeraÃ§Ã£o de Embeddings**: Usando OpenAI ou Azure OpenAI
- **Vector Store**: Armazenamento e busca em ChromaDB
- **API REST**: Endpoints para extraÃ§Ã£o, busca e gerenciamento

## ğŸ“‹ PrÃ©-requisitos

- Node.js 18+
- Docker e Docker Compose
- OpenAI API Key ou Azure OpenAI

## ğŸ› ï¸ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone <repository-url>
cd data-intake
```

2. **Instale as dependÃªncias**
```bash
npm install
```

3. **Configure as variÃ¡veis de ambiente**
```bash
cp env.example .env.local
# Edite o arquivo .env.local com suas configuraÃ§Ãµes

# OU use o arquivo de configuraÃ§Ã£o YAML (recomendado)
cp config.example.yml .env.yml
# Edite o arquivo .env.yml com suas configuraÃ§Ãµes
```

4. **Inicie o ChromaDB**
```bash
docker-compose up -d chromadb
```

5. **Execute o projeto**
```bash
# Desenvolvimento
npm run start:dev

# ProduÃ§Ã£o
npm run build
npm run start:prod
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# Ambiente
NODE_ENV=local

# OpenAI/Azure OpenAI
OPENAI_API_KEY=your_openai_api_key
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name

# ChromaDB
CHROMA_URL=http://localhost:8000
CHROMA_COLLECTION_NAME=documents

# Logging
LOG_LEVEL=info
```

### ConfiguraÃ§Ã£o YAML (Recomendado)

Para melhor organizaÃ§Ã£o, vocÃª pode usar o arquivo `.env.yml`:

```yaml
# ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
server:
  port: 3000
  node_env: local

# ConfiguraÃ§Ãµes do OpenAI
openai:
  api_key: your_openai_api_key

# ConfiguraÃ§Ãµes do Azure OpenAI
azure_openai:
  api_key: your_azure_openai_api_key
  endpoint: https://your-resource.openai.azure.com
  deployment_name: your-deployment-name

# ConfiguraÃ§Ãµes do ChromaDB
chromadb:
  url: http://localhost:8000
  collection_name: documents

# ConfiguraÃ§Ãµes de logging
logging:
  level: info
```

## ğŸ“š Uso da API

### Extrair Documento
```bash
POST /api/v1/extraction
```

```json
{
  "source": "/path/to/document.pdf",
  "fileType": "pdf",
  "chunkingStrategy": "recursive",
  "chunkSize": 1000,
  "chunkOverlap": 200,
  "metadata": {
    "author": "JoÃ£o Silva",
    "category": "financeiro"
  },
  "saveToVectorStore": true
}
```

### Buscar Documentos Similares
```bash
POST /api/v1/extraction/search
```

```json
{
  "query": "Como funciona o processo de aprovaÃ§Ã£o?",
  "k": 5,
  "filter": {
    "fileType": "pdf"
  }
}
```

### Listar ExtraÃ§Ãµes
```bash
GET /api/v1/extraction?limit=10&offset=0
```

### Obter ExtraÃ§Ã£o EspecÃ­fica
```bash
GET /api/v1/extraction/{id}
```

## ğŸ”„ Fluxo de Processamento

1. **Carregamento**: Documento Ã© carregado usando LangChain loaders
2. **Chunking**: Texto Ã© dividido em chunks menores
3. **Embeddings**: Cada chunk recebe um embedding vetorial
4. **Armazenamento**: Chunks sÃ£o salvos no ChromaDB (opcional)
5. **Resposta**: API retorna chunks com metadados e embeddings

## ğŸ“Š EstratÃ©gias de Chunking

1. **Recursive**: Divide o texto de forma recursiva usando separadores
2. **Token**: Divide baseado em tokens (recomendado para LLMs)
3. **Character**: Divide baseado em caracteres

## ğŸ“„ Tipos de Arquivo Suportados

- **PDF**: Usando pdf-parse
- **Excel**: Usando xlsx (todas as planilhas)
- **Texto**: Arquivos .txt
- **HTML**: Arquivos .html (extraÃ§Ã£o bÃ¡sica de texto)

## ğŸ³ Docker

### ChromaDB
```bash
# Iniciar ChromaDB
docker-compose up -d chromadb

# Verificar status
docker-compose ps

# Logs
docker-compose logs chromadb
```

## ğŸ“ˆ Monitoramento

O projeto inclui logs detalhados para:
- Carregamento de documentos
- Processo de chunking
- GeraÃ§Ã£o de embeddings
- OperaÃ§Ãµes do vector store
- Tempo de processamento

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

Para suporte, abra uma issue no repositÃ³rio ou entre em contato com a equipe de desenvolvimento.

## ğŸ§ª Testes

```bash
# Testes unitÃ¡rios
npm run test:unit

# Testes do mÃ³dulo de extraÃ§Ã£o
npm run extraction:test

# Testes e2e
npm run test:e2e

# Cobertura de testes
npm run test:cov
```

## ğŸ“– Exemplos

### Executar Exemplo de ExtraÃ§Ã£o
```bash
npm run extraction:example
```

Este comando executa um script de exemplo que demonstra:
- ExtraÃ§Ã£o de documentos PDF e Excel
- Busca semÃ¢ntica no vector store
- Filtros e metadados
- EstatÃ­sticas da coleÃ§Ã£o

## ğŸ—ï¸ Arquitetura

```
src/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ config/           # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ health/           # Health checks
â”‚   â”œâ”€â”€ extraction/       # MÃ³dulo de extraÃ§Ã£o
â”‚   â””â”€â”€ common/           # Filtros e utilitÃ¡rios
â””â”€â”€ main.ts              # Ponto de entrada da aplicaÃ§Ã£o
```